{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia as wp\n",
    "from wikipedia.exceptions import DisambiguationError, PageError\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import numpy as np\n",
    "import requests\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DT'), ('subset', 'JJ'), ('recombination', 'NN'), ('events', 'NNS'), ('results', 'NNS'), ('crossovers', 'NNS'), (',', ','), Tree('REL_PHRASE', [('create', 'VB')]), ('physical', 'JJ'), ('links', 'NNS'), Tree('REL_PHRASE', [('known', 'VBN')]), ('chiasmata', 'NNS'), ('(', '('), ('singular', 'JJ'), (':', ':'), ('chiasma', 'NN'), (',', ','), ('Greek', 'JJ'), ('letter', 'NN'), ('Chi', 'NNP'), ('(', '('), ('X', 'NNP'), (')', ')'), (')', ')'), ('homologous', 'JJ'), ('chromosomes', 'NNS'), ('.', '.')]\n",
      "crossovers\n",
      "(REL_PHRASE create/VB)\n",
      "links\n",
      "(REL_PHRASE known/VBN)\n",
      "chromosomes\n",
      "('.', '.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['crossovers',\n",
       " Tree('REL_PHRASE', [('create', 'VB')]),\n",
       " 'links',\n",
       " Tree('REL_PHRASE', [('known', 'VBN')]),\n",
       " 'chromosomes',\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_ignore = set(stopwords.words('english'))\n",
    "sentence = \"A subset of recombination events results in crossovers, which create physical links known as chiasmata (singular: chiasma, for the Greek letter Chi (X)) between the homologous chromosomes.\"\n",
    "sentence = ' '.join(map(lambda x: x if x not in to_ignore else '', sentence.split(' ')))\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "token_pos = nltk.pos_tag(tokens)\n",
    "verb = \"<VB|VBG|VBN|VBP|VBZ>*<RB|RBR|RBS>*\"\n",
    "word = \"<NN|NNS|NNP|NNPS|JJ|JJR|JJS|RB|WP>\"\n",
    "preposition = \"<IN>\"\n",
    "rel_pattern = \"({}|{}{}|{}{}*{})+ \".format(verb, verb, preposition, verb, word, preposition)\n",
    "grammar_long = '''REL_PHRASE: {%s}''' % rel_pattern\n",
    "reverb_pattern = nltk.RegexpParser(grammar_long)\n",
    "tree = list(reverb_pattern.parse(token_pos))\n",
    "print(tree)\n",
    "\n",
    "def iterate_over(tree):\n",
    "    indices = list(filter(lambda y: y != -1, list(map(lambda x: tree.index(x) if type(x) == nltk.tree.Tree or x[1] == '.' else -1, tree))))\n",
    "    return indices\n",
    "\n",
    "indices = iterate_over(tree)\n",
    "result = []\n",
    "\n",
    "start = 0\n",
    "for i in range(len(indices)):\n",
    "    end = indices[i]\n",
    "    sub_list = list(filter(lambda x: x[1] in ['NN', 'NNS', 'NNP'], tree[start:end]))\n",
    "    last_noun = sub_list[-1][0] if len(sub_list) > 0 else None\n",
    "    print(last_noun)\n",
    "    print(tree[indices[i]])\n",
    "    \n",
    "    if(len(sub_list) > 0):\n",
    "        result.append(last_noun)\n",
    "        result.append(tree[end])\n",
    "    start = end + 1\n",
    "\n",
    "result\n",
    "\n",
    "# iterate over\n",
    "# last NNS/NN if it exists followed by whatever is before REL_PHARSE\n",
    "# REL_PHRASE\n",
    "\n",
    "# note how stage is a common noun that refers to a proper noun\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_or_child(topic1, topic2): #returns 1 if topic1 is parent of topic2\n",
    "    try:\n",
    "        topic1_content = wp.page(topic1).content\n",
    "        topic2_content = wp.page(topic2).content\n",
    "        count2in1 = topic1_content.count(topic2) / len(topic1_content)\n",
    "        count1in2 = topic2_content.count(topic1) / len(topic2_content)\n",
    "        if count2in1 == 0 and count1in2 == 0:\n",
    "            return 0\n",
    "        elif count1in2 > count2in1:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    except DisambiguationError or PageError:\n",
    "        return -2\n",
    "\n",
    "# title = \"meiosis\"\n",
    "# page = wp.page(title)\n",
    "# content = ''.join(i for i in page.content if ord(i) < 128)\n",
    "# sents = list(map(lambda x: x.strip(' '), content.split('.')))\n",
    "\n",
    "# for link in page.links:\n",
    "#     comp = parent_or_child(title, link)\n",
    "#     if comp > 0:\n",
    "#         print(title, \"is parent of\", link)\n",
    "#     elif comp < 0:\n",
    "#         print(link, \"is parent of\", title)\n",
    "#     elif comp == 0:\n",
    "#         print(title, link, \"are siblings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet(sent):\n",
    "    url = \"http://www.newventify.com/rdf?sentence=\"\n",
    "    r = requests.get(url + sent)\n",
    "    try:\n",
    "        rdf = r.json()['rdf']\n",
    "        print(\"triplet gotten\")\n",
    "    except JSONDecodeError:\n",
    "        return []\n",
    "    return rdf\n",
    "\n",
    "# for sent in sents:\n",
    "#     trip = get_triplet(sent)\n",
    "#     if title in trip:\n",
    "#         print(trip)\n",
    "#         print(sent)\n",
    "\n",
    "# sents = [get_triplet(sent) for sent in sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import to_unicode\n",
    "\n",
    "file_name = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(file_name, binary=True, encoding='utf-8', unicode_errors = 'ignore') \n",
    "# # if you vector file is in binary format, change to binary=True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in words:\n",
    "        if word in model.wv.vocab:\n",
    "            tokens.append(model[word])\n",
    "            labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# removes parantheses and spaces\n",
    "def replace_parantheses(pre_string):\n",
    "#     if pre_string.count('(') > pre_string.count(')'):\n",
    "#         first_ind = pre_string.index('(')\n",
    "#         return replace_parantheses(pre_string[:first_ind] + pre_string[first_ind + 1:])\n",
    "    re_match = \"\\(.*\\)\" # anything besides ')'\n",
    "    re_space = \"\\s\\s+\"\n",
    "    return re.sub(re_space, ' ', re.sub(re_match, '', pre_string)).replace('\\n', ' ')\n",
    "\n",
    "def get_all_sents(title):\n",
    "    try:\n",
    "        page = wp.page(title)\n",
    "    except DisambiguationError or PageError:\n",
    "        return []\n",
    "    content = ''.join(i for i in page.content if ord(i) < 128)\n",
    "    con = replace_parantheses(content)\n",
    "    sents = sent_tokenize(con)\n",
    "    return sents, content\n",
    "\n",
    "def get_valid_triplets(sents):\n",
    "    triplets = [get_triplet(sent) for sent in sents]\n",
    "    np_triplets = np.array(triplets)\n",
    "    np_triplets = [np_triplets[i] if (np_triplets[i] != \"\").all() else [] for i in range(len(np_triplets))]\n",
    "    return np.array(np_triplets).tolist()\n",
    "\n",
    "def get_relevant_terms(title):\n",
    "    try:\n",
    "        page = wp.page(title)\n",
    "    except DisambiguationError or PageError:\n",
    "        return []\n",
    "    return page.links # and those with high cosine scores from our word2vec\n",
    "\n",
    "sents, content = get_all_sents(\"meiosis\")\n",
    "# sents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n"
     ]
    }
   ],
   "source": [
    "relevant_sents = [sent for sent in sents if \"meiosis\" in sent.lower()] # all sents with meiosis in it\n",
    "relevant_triplets = get_valid_triplets(relevant_sents[20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThe term was linguistically corrected to \"meiosis\" by Koernicke, and by Pantel and De Sinety.',\n",
       " '\\n\\n\\n== Phases ==\\nMeiosis is divided into meiosis I and meiosis II which are further divided into Karyokinesis I and Cytokinesis I and Karyokinesis II and Cytokinesis II respectively.',\n",
       " 'The preparatory steps that lead up to meiosis are identical in pattern and name to interphase of the mitotic cell cycle.',\n",
       " 'This will take place during prophase I in meiosis.',\n",
       " '\\nGrowth 2 phase: G2 phase as seen before mitosis is not present in meiosis.',\n",
       " 'Interphase is followed by meiosis I and then meiosis II.',\n",
       " 'Meiosis I separates homologous chromosomes, each still made up of two sister chromatids, into two daughter cells, thus reducing the chromosome number by half.',\n",
       " 'During meiosis II, sister chromatids decouple and the resultant daughter chromosomes are segregated into four daughter cells.',\n",
       " 'For diploid organisms, the daughter cells resulting from meiosis are haploid and contain only one copy of each chromosome.',\n",
       " 'In some species, cells enter a resting phase known as interkinesis between meiosis I and meiosis II.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_sents[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['term' 'corrected' 'meiosis']\n",
      "term is of relation sibling to meiosis\n",
      "['steps' 'lead' 'meiosis']\n",
      "steps is of relation sibling to meiosis\n",
      "['This' 'take' 'place']\n",
      "This is of relation parent to place\n",
      "['Growth' 'seen' 'mitosis']\n",
      "Growth is of relation sibling to mitosis\n",
      "['Interphase' 'followed' 'I']\n",
      "Interphase is of relation sibling to I\n",
      "['I' 'separates' 'chromosomes']\n",
      "I is of relation parent to chromosomes\n",
      "['meiosis' 'segregated' 'daughter']\n",
      "meiosis is of relation child to daughter\n",
      "['organisms' 'resulting' 'meiosis']\n",
      "organisms is of relation sibling to meiosis\n",
      "['species' 'known' 'interkinesis']\n",
      "species is of relation parent to interkinesis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_words = [\"includes\", \"contains\"]\n",
    "sibling_words = [\"causes\", \"caused\"]\n",
    "child_words = [\"suchas\"]\n",
    "\n",
    "def max_sim(relation, pred):\n",
    "    if relation in [\"parent\", \"sibling\", \"child\"]:\n",
    "        return sum([model.similarity(pred, word) for word in globals()[\"{}_words\".format(relation)]]) / len(globals()[\"{}_words\".format(relation)])\n",
    "\n",
    "def best_relation(pred):\n",
    "    return max([\"parent\", \"sibling\", \"child\"], key = lambda x: max_sim(x, pred))\n",
    "\n",
    "def subject_relation(triplet):\n",
    "    return best_relation(triplet[1])\n",
    "    \n",
    "for triplet in relevant_triplets:\n",
    "    if len(triplet) > 0:\n",
    "        pred = triplet[1]\n",
    "        print(triplet)\n",
    "        print(triplet[0], \"is of relation\", best_relation(triplet[1]), \"to\", triplet[2])\n",
    "\n",
    "\n",
    "# THIS WORKS WELL DIFFERENTIATING BETWEEN HIGHER/LOWER LEVEL AND SIBLING LEVEL\n",
    "# BUT NOT SO WELL BETWEEN PARENT AND CHILD\n",
    "\n",
    "\n",
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cohesion | is released During | Meiosis II', 'cohesion | is | released'],\n",
       " [],\n",
       " ['cell | produce | ovum'],\n",
       " [],\n",
       " [],\n",
       " ['alternating cycles | Thus enable reproduction with | generations',\n",
       "  'cycles | enable with | generations',\n",
       "  'cycles | enable reproduction with | generations',\n",
       "  'alternating cycles | Thus enable with | successive generations',\n",
       "  'cycles | Thus enable | sexual reproduction',\n",
       "  'alternating cycles | enable | reproduction',\n",
       "  'maintaining | number of | chromosomes',\n",
       "  'alternating cycles | enable reproduction with | generations',\n",
       "  'alternating cycles | enable with | successive generations',\n",
       "  'alternating cycles | Thus enable reproduction with | successive generations',\n",
       "  'cycles | enable reproduction with | successive generations',\n",
       "  'alternating cycles | enable | sexual reproduction',\n",
       "  'alternating cycles | Thus enable | sexual reproduction',\n",
       "  'cycles | Thus enable reproduction with | generations',\n",
       "  'cycles | Thus enable reproduction with | successive generations',\n",
       "  'alternating cycles | enable reproduction with | successive generations',\n",
       "  'cycles | Thus enable with | generations',\n",
       "  'alternating cycles | Thus enable with | generations',\n",
       "  'alternating cycles | enable with | generations',\n",
       "  'cycles | enable with | successive generations',\n",
       "  'cycles | Thus enable with | successive generations',\n",
       "  'cycles | enable | reproduction',\n",
       "  'alternating cycles | Thus enable | reproduction',\n",
       "  'maintaining | same number of | chromosomes',\n",
       "  'cycles | Thus enable | reproduction',\n",
       "  'cycles | enable | sexual reproduction'],\n",
       " ['human cells | contain | 23 pairs of chromosomes',\n",
       "  'cells | contain | 23 pairs of chromosomes including 1 pair of sex chromosomes',\n",
       "  'cells | contain | 23 pairs of chromosomes',\n",
       "  'diploid cells | contain | 23 pairs',\n",
       "  'chromosomes | of pairs is | half',\n",
       "  'diploid human cells | contain | 23 pairs of chromosomes',\n",
       "  'diploid human cells | contain | 23 pairs of chromosomes including 1 pair of sex chromosomes',\n",
       "  'cells | contain | 23 pairs of chromosomes including 1 pair',\n",
       "  'diploid cells | contain | half of origin',\n",
       "  'diploid human cells | contain | 23 pairs of chromosomes including 1 pair',\n",
       "  'human cells | contain | half of origin',\n",
       "  'diploid cells | contain | 23 pairs of chromosomes including 1 pair',\n",
       "  'human cells | contain | half',\n",
       "  'human cells | contain | 23 pairs of chromosomes including 1 pair',\n",
       "  'cells | contain | half',\n",
       "  'diploid human cells | contain | 23 pairs',\n",
       "  'diploid cells | contain | 23 pairs of chromosomes',\n",
       "  'cells | contain | half of maternal origin',\n",
       "  'diploid human cells | contain | half of maternal origin',\n",
       "  'human cells | contain | half of maternal origin',\n",
       "  'cells | contain | half of origin',\n",
       "  'diploid cells | contain | half',\n",
       "  '23 pairs | half of | maternal origin',\n",
       "  'cells | contain | 23 pairs',\n",
       "  'human cells | contain | 23 pairs',\n",
       "  'human cells | contain | 23 pairs of chromosomes including 1 pair of sex chromosomes',\n",
       "  'diploid human cells | contain | half of origin',\n",
       "  'diploid cells | contain | half of maternal origin',\n",
       "  'diploid human cells | contain | half',\n",
       "  'diploid cells | contain | 23 pairs of chromosomes including 1 pair of sex chromosomes'],\n",
       " [],\n",
       " [],\n",
       " ['process | is related to | more general cell division process of mitosis',\n",
       "  'process | is related to | general cell division process of mitosis']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def get_openie_triplets(sents):\n",
    "    openie_triplets = []\n",
    "    for i in range(len(sents)):\n",
    "        sent = sents[i]\n",
    "        cmd = \"cd Stanford-OpenIE-Python; echo \\“\" + sent + \"\\” > samples.txt; python main.py -f samples.txt\"\n",
    "        trip_array = os.popen(cmd).read().split('\\n')\n",
    "        trip_array = np.array(trip_array)[np.array(trip_array) != ''].tolist()\n",
    "        openie_triplets.append(trip_array)\n",
    "    return openie_triplets\n",
    "\n",
    "triplets = get_openie_triplets(sents[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n",
      "triplet gotten\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['cell', 'undergoes', 'DNA'],\n",
       "  ['each', 'leading', 'connections'],\n",
       "  ['division', 'separate', 'daughter'],\n",
       "  ['cells', 'proceed', 'division'],\n",
       "  ['sister', 'produce', 'total'],\n",
       "  ['animals', 'employ', 'variation'],\n",
       "  ['recombination', 'are', 'distinct'],\n",
       "  ['gamete', 'include', 'assortment'],\n",
       "  ['diversity', 'resulting', 'reproduction'],\n",
       "  ['Meiosis', 'used', 'eukaryotes']],\n",
       " [['homolog | consists of | two sister chromatids',\n",
       "   'homolog | now consists of | two identical sister chromatids',\n",
       "   'homolog | now consists of | two sister chromatids',\n",
       "   'homolog | consists of | two identical sister chromatids'],\n",
       "  ['set | is with | other DNA'],\n",
       "  ['homologs | are segregated In | meiotic division',\n",
       "   'homologs | are | segregated',\n",
       "   'homologs | are segregated In | first division',\n",
       "   'homologs | are segregated In | first meiotic division',\n",
       "   'homologs | separate | daughter cells',\n",
       "   'homologs | are segregated In | division',\n",
       "   'homologs | separate daughter cells by | spindle apparatus'],\n",
       "  ['cells | proceed without | round of DNA replication',\n",
       "   'cells | proceed without | round',\n",
       "   'cells | proceed to | division',\n",
       "   'cells | proceed to | second division',\n",
       "   'cells | proceed without | intervening round of DNA replication',\n",
       "   'cells | proceed without | intervening round'],\n",
       "  ['sister chromatids | separate | daughter cells'],\n",
       "  ['animals | employ | slight variation',\n",
       "   'animals | produce | one large ovum',\n",
       "   'Female animals | employ | slight variation',\n",
       "   'animals | produce | one ovum',\n",
       "   'animals | employ | variation',\n",
       "   'Female animals | employ | variation',\n",
       "   'Female animals | produce | one ovum',\n",
       "   'Female animals | produce | one large ovum'],\n",
       "  ['individual chromatid | can consist of | new combination of maternal DNA',\n",
       "   'individual chromatid | can consist of | new combination',\n",
       "   'individual chromatid | can consist of | new combination of DNA',\n",
       "   'chromatid | can consist Because of | recombination',\n",
       "   'chromatid | can consist of | new combination',\n",
       "   'chromatid | can consist of | new combination of DNA',\n",
       "   'individual chromatid | can consist Because of | recombination',\n",
       "   'chromatid | can consist of | combination of DNA',\n",
       "   'chromatid | can consist of | combination',\n",
       "   'individual chromatid | can consist of | combination',\n",
       "   'individual chromatid | can consist of | combination of DNA',\n",
       "   'chromatid | can consist of | new combination of maternal DNA',\n",
       "   'individual chromatid | can consist of | combination of maternal DNA',\n",
       "   'chromatid | can consist | resulting',\n",
       "   'individual chromatid | can consist | resulting',\n",
       "   'chromatid | can consist of | combination of maternal DNA'],\n",
       "  ['individual gamete | Furthermore can include | assortment of maternal chromatids',\n",
       "   'gamete | can include | assortment',\n",
       "   'individual gamete | can include | assortment of maternal chromatids',\n",
       "   'individual gamete | Furthermore can include | assortment',\n",
       "   'gamete | Furthermore can include | assortment of maternal chromatids',\n",
       "   'gamete | Furthermore can include | assortment',\n",
       "   'gamete | can include | assortment of chromatids',\n",
       "   'gamete | Furthermore can include | assortment of chromatids',\n",
       "   'individual gamete | can include | assortment of chromatids',\n",
       "   'individual gamete | Furthermore can include | assortment of chromatids',\n",
       "   'gamete | can include | assortment of maternal chromatids',\n",
       "   'individual gamete | can include | assortment'],\n",
       "  ['variation | is in | traits'],\n",
       "  []])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for sent in sents\n",
    "#     get triplet\n",
    "#     get openie_triplets\n",
    "#     get expanded subject, object from openie_triplet\n",
    "#     find highest predicate score of any category of valid openie_triplets\n",
    "\n",
    "# for i in range((len(sents) + 10) // 10):\n",
    "i = 1\n",
    "batch = sents[10 * i: min(len(sents), 10 * (i + 1))]\n",
    "triplets = get_valid_triplets(batch)\n",
    "openie_triplets = get_openie_triplets(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['recombination', 'are', 'distinct'],\n",
       " ['individual chromatid | can consist of | new combination of maternal DNA',\n",
       "  'individual chromatid | can consist of | new combination',\n",
       "  'individual chromatid | can consist of | new combination of DNA',\n",
       "  'chromatid | can consist Because of | recombination',\n",
       "  'chromatid | can consist of | new combination',\n",
       "  'chromatid | can consist of | new combination of DNA',\n",
       "  'individual chromatid | can consist Because of | recombination',\n",
       "  'chromatid | can consist of | combination of DNA',\n",
       "  'chromatid | can consist of | combination',\n",
       "  'individual chromatid | can consist of | combination',\n",
       "  'individual chromatid | can consist of | combination of DNA',\n",
       "  'chromatid | can consist of | new combination of maternal DNA',\n",
       "  'individual chromatid | can consist of | combination of maternal DNA',\n",
       "  'chromatid | can consist | resulting',\n",
       "  'individual chromatid | can consist | resulting',\n",
       "  'chromatid | can consist of | combination of maternal DNA'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets[6], openie_triplets[6]\n",
    "\n",
    "# this is surprising, very few subject, object pair from triplet is contained entirely in its openie_triplets counterpart\n",
    "# but its clear openie_triplets outperform triplets\n",
    "\n",
    "# weight an idf for openie_triplets predicates in order to calculate score\n",
    "\n",
    "def predicate_idf(pred):\n",
    "    tokens = pred.split(' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Meiosis', 'between', 'the', 'homologous', 'chromosomes', '.']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary(' '.join(sents))\n",
    "\n",
    "word_tokenize(sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrape_venv",
   "language": "python",
   "name": "scrape_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
